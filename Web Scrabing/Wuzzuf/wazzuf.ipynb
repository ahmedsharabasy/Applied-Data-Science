{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9bd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests  \n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a23170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "for i in range(2):\n",
    "    results = requests.get(f\"https://wuzzuf.net/search/jobs/?a=navbg&q=data%20analyst&start={i}\")\n",
    "    src =results.content   # all code > byte code\n",
    "    soup=BeautifulSoup(src, 'lxml')\n",
    "#    page_num+=1\n",
    "    \n",
    "#     page_limit=int(soup.find(\"strong\").text)\n",
    "#     if (page_num > page_limit // 15):\n",
    "#         break\n",
    "    \n",
    "    title=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    posted=[]\n",
    "    skills=[]\n",
    "    linkss=[]\n",
    "    links_end=[]\n",
    "\n",
    "\n",
    "    job_title = soup.find_all(\"h2\",{'class':\"css-m604qf\"})#.find_all(\"a\",{\"class\":\"css-o171kl\"}).text.strip()\n",
    "    job_company = soup.find_all(\"a\",{'class':\"css-17s97q8\"})\n",
    "    job_location = soup.find_all(\"span\",{'class':\"css-5wys0k\"})\n",
    "    job_skills = soup.find_all(\"div\",{'class':\"css-y4udm8\"})\n",
    "    #     job_responsibility = soup.find_all(\"div\",{'class':\"css-do6t5g\"})\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(job_title)):\n",
    "        title.append(job_title[i].text)\n",
    "        linkss.append(job_title[i].find(\"a\").attrs['href'])\n",
    "        links = str(\"https://wuzzuf.net\")+str(linkss[i])\n",
    "        links_end.append(links)\n",
    "        company.append(job_company[i].text)\n",
    "        location.append(job_location[i].text)\n",
    "        skills.append(job_skills[i].text)  \n",
    "\n",
    "    for link in links_end:\n",
    "        result = requests.get(link)\n",
    "        src = result.content   \n",
    "        soupp = BeautifulSoup(src, 'lxml')\n",
    "    #     job_applications=soupp.find(\"div\",{\"class\":\"css-1wb134k\"})\n",
    "    #     applications.append(job_applications)\n",
    "\n",
    "\n",
    "file_list=[title,company,location,skills,links_end]\n",
    "output=zip_longest(*file_list)\n",
    "\n",
    "with open(\"C:\\\\Users\\\\20100\\\\Desktop\\\\data science\\\\Applied Data Science\\\\Web Scrabing\\\\Wuzzuf\\\\wazzuf.csv\",\"w\") as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"job title\",\"job company\",\"job location\",\"job skills\",\"links\"])\n",
    "    wr.writerows(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283994c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df0ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
